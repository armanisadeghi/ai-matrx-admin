{
  "description": "Comprehensive settings schema for Python backend team",
  "maximimum_possible_configuration": {
    "model_id": "548126f2-714a-4562-9001-0c31cbeea375",
    "output_format": "text",
    "tool_choice": "auto",
    "tools": [],
    "temperature": 1,
    "max_tokens": 4096,
    "top_p": 1,
    "top_k": 50,
    "store": true,
    "stream": true,
    "parallel_tool_calls": false,
    "image_urls": false,
    "file_urls": false,
    "internal_web_search": false,
    "youtube_videos": false,
    "reasoning_effort": "medium",
    "verbosity": "medium",
    "reasoning_summary": "auto",
    "stop_sequences": []
  },
  "schema": {
    "model_id": {
      "type": "string",
      "format": "uuid",
      "required": true,
      "description": "The unique identifier for the AI model to use"
    },
    "output_format": {
      "type": "string",
      "enum": ["text", "json_object", "json_schema"],
      "required": false,
      "default": "text",
      "description": "Controls the response format"
    },
    "tool_choice": {
      "type": "string",
      "enum": ["auto", "required", "none"],
      "required": false,
      "default": "auto",
      "description": "Controls how tools are used"
    },
    "tools": {
      "type": "array",
      "items": "string",
      "required": false,
      "default": [],
      "description": "Array of tool identifiers to make available to the model"
    },
    "temperature": {
      "type": "number",
      "min": 0,
      "max": 2,
      "required": false,
      "default": 1,
      "description": "Controls randomness in responses"
    },
    "max_tokens": {
      "type": "number",
      "min": 1,
      "max": "model-dependent",
      "required": false,
      "default": 4096,
      "description": "Maximum number of tokens to generate"
    },
    "top_p": {
      "type": "number",
      "min": 0,
      "max": 1,
      "required": false,
      "default": 1,
      "description": "Nucleus sampling parameter"
    },
    "top_k": {
      "type": "number",
      "min": 1,
      "max": 100,
      "required": false,
      "default": 50,
      "description": "Sampling parameter. Limits the number of top tokens"
    },
    "store": {
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "Whether to store the conversation in the database"
    },
    "stream": {
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "Whether to stream the response in real-time"
    },
    "parallel_tool_calls": {
      "type": "boolean",
      "required": false,
      "default": false,
      "description": "Whether to allow the model to call multiple tools simultaneously"
    },
    "image_urls": {
      "type": "boolean",
      "required": false,
      "default": false,
      "description": "Enable the model to process and analyze images via URLs"
    },
    "file_urls": {
      "type": "boolean",
      "required": false,
      "default": false,
      "description": "Enable the model to process and analyze files via URLs"
    },
    "internal_web_search": {
      "type": "boolean",
      "required": false,
      "default": false,
      "description": "Enable web search capability for real-time information"
    },
    "youtube_videos": {
      "type": "boolean",
      "required": false,
      "default": false,
      "description": "Enable processing and analysis of YouTube videos"
    },
    "reasoning_effort": {
      "type": "string",
      "enum": ["none", "low", "medium", "high"],
      "required": false,
      "default": "medium",
      "description": "For reasoning models. Controls computational effort"
    },
    "verbosity": {
      "type": "string",
      "enum": ["low", "medium", "high"],
      "required": false,
      "default": "medium",
      "description": "For reasoning models. Controls detail level of reasoning output"
    },
    "reasoning_summary": {
      "type": "string",
      "enum": ["auto", "enabled", "disabled"],
      "required": false,
      "default": "auto",
      "description": "For reasoning models. Controls whether reasoning steps are summarized"
    },
    "stop_sequences": {
      "type": "array",
      "items": "string",
      "required": false,
      "default": [],
      "description": "Array of sequences that will stop token generation"
    }
  },
  "all_possible_values": {
    "output_format": ["text", "json_object", "json_schema"],
    "tool_choice": ["auto", "required", "none"],
    "tools": "array of tool name strings",
    "temperature": "number 0-2",
    "max_tokens": "number 1-32000 (model dependent)",
    "top_p": "number 0-1",
    "top_k": "number 1-100",
    "store": "boolean",
    "stream": "boolean",
    "parallel_tool_calls": "boolean",
    "image_urls": "boolean",
    "file_urls": "boolean",
    "internal_web_search": "boolean",
    "youtube_videos": "boolean",
    "reasoning_effort": ["none", "low", "medium", "high"],
    "verbosity": ["low", "medium", "high"],
    "reasoning_summary": ["auto", "enabled", "disabled"],
    "stop_sequences": "array of strings"
  },
  "notes_for_python_backend": [
    "Only model_id is required - all other fields are optional",
    "Booleans default to: store=true, stream=true",
    "Arrays (tools, stop_sequences) are always arrays - never null",
    "Numbers should be validated against their ranges",
    "Enums should be validated against allowed values",
    "Some settings are model-specific (reasoning_* only for o1-series)",
    "attachment flags (image_urls, file_urls, etc.) may be model-specific"
  ],
  "minimum_configuration": {
    "model_id": "548126f2-714a-4562-9001-0c31cbeea375",
    "stream": true
  },
  "common_presets": {
    "default": {
      "model_id": "548126f2-714a-4562-9001-0c31cbeea375",
      "stream": true,
      "store": true,
      "temperature": 1,
      "max_tokens": 4096
    },
    "json_mode": {
      "model_id": "548126f2-714a-4562-9001-0c31cbeea375",
      "stream": true,
      "store": true,
      "output_format": "json_object",
      "temperature": 0.7,
      "max_tokens": 4096
    },
    "with_tools": {
      "model_id": "548126f2-714a-4562-9001-0c31cbeea375",
      "stream": true,
      "store": true,
      "tools": ["tool1", "tool2"],
      "tool_choice": "auto",
      "parallel_tool_calls": true,
      "temperature": 0.7,
      "max_tokens": 4096
    }
  }
}

